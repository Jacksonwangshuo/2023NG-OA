{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ed87c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc0b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train data and split into labels and features\n",
    "train_data = pd.read_csv('data_science_challenge/data_science_challenge/train.csv', header=None, names=['col1', 'col2', 'col3', 'col4', 'col5', 'col6'])\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('data_science_challenge/data_science_challenge/test.csv', header=None, names=['col1', 'col2', 'col3', 'col4', 'col5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e32179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   col1    1000000 non-null  object \n",
      " 1   col2    1000000 non-null  object \n",
      " 2   col3    1000000 non-null  float64\n",
      " 3   col4    1000000 non-null  float64\n",
      " 4   col5    1000000 non-null  float64\n",
      " 5   col6    1000000 non-null  int64  \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 45.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b94d4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.498577</td>\n",
       "      <td>3.502040</td>\n",
       "      <td>3.502117</td>\n",
       "      <td>0.296819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.022159</td>\n",
       "      <td>2.019445</td>\n",
       "      <td>2.020394</td>\n",
       "      <td>0.456856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 col3            col4            col5            col6\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000\n",
       "mean         3.498577        3.502040        3.502117        0.296819\n",
       "std          2.022159        2.019445        2.020394        0.456856\n",
       "min          0.000000        0.000000        0.000000        0.000000\n",
       "25%          1.750000        1.760000        1.750000        0.000000\n",
       "50%          3.500000        3.500000        3.510000        0.000000\n",
       "75%          5.250000        5.250000        5.250000        1.000000\n",
       "max          7.000000        7.000000        7.000000        1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Description\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dab9e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\Anaconda\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='col6', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(train_data['col6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9e501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Encoding (for column 'col2')\n",
    "\n",
    "#For training dataset\n",
    "one_hot = pd.get_dummies(train_data['col2'])\n",
    "\n",
    "new_train_data = pd.concat([train_data, one_hot], axis=1)\n",
    "\n",
    "new_train_data.drop('col1', axis=1, inplace=True)\n",
    "new_train_data.drop('col2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2bf0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Encoding (for column 'col2')\n",
    "\n",
    "#For testing dataset\n",
    "one_hot = pd.get_dummies(test_data['col2'])\n",
    "\n",
    "new_test_data = pd.concat([test_data, one_hot], axis=1)\n",
    "\n",
    "new_test_data.drop('col1', axis=1, inplace=True)\n",
    "new_test_data.drop('col2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e791736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>akron</th>\n",
       "      <th>alameda</th>\n",
       "      <th>albany</th>\n",
       "      <th>alexandria</th>\n",
       "      <th>alhambra</th>\n",
       "      <th>allen</th>\n",
       "      <th>amarillo</th>\n",
       "      <th>...</th>\n",
       "      <th>whittier</th>\n",
       "      <th>wichita</th>\n",
       "      <th>wichita falls</th>\n",
       "      <th>wilmington</th>\n",
       "      <th>worcester</th>\n",
       "      <th>wyoming</th>\n",
       "      <th>yakima</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yorba linda</th>\n",
       "      <th>yuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.30</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.37</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.44</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.89</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.60</td>\n",
       "      <td>6.03</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.30</td>\n",
       "      <td>0.51</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.71</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6.92</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6.90</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     col3  col4  col5  akron  alameda  albany  alexandria  alhambra  allen  \\\n",
       "0    2.30  3.77  1.21      0        0       0           0         0      0   \n",
       "1    4.37  0.61  4.57      0        0       0           0         0      0   \n",
       "2    1.44  4.68  4.51      0        0       0           0         0      0   \n",
       "3    3.39  0.20  6.06      0        0       0           0         0      0   \n",
       "4    2.89  4.22  1.90      0        0       0           0         0      0   \n",
       "..    ...   ...   ...    ...      ...     ...         ...       ...    ...   \n",
       "995  2.60  6.03  5.32      0        0       0           0         0      0   \n",
       "996  1.30  0.51  6.81      0        0       0           0         0      0   \n",
       "997  1.71  3.49  2.63      0        0       0           0         0      0   \n",
       "998  6.92  4.36  4.61      0        0       0           0         0      0   \n",
       "999  6.90  0.79  4.17      0        0       0           0         0      0   \n",
       "\n",
       "     amarillo  ...  whittier  wichita  wichita falls  wilmington  worcester  \\\n",
       "0           0  ...         0        0              0           0          0   \n",
       "1           0  ...         0        0              0           0          0   \n",
       "2           0  ...         0        0              0           0          0   \n",
       "3           0  ...         0        0              0           0          0   \n",
       "4           0  ...         0        0              0           0          0   \n",
       "..        ...  ...       ...      ...            ...         ...        ...   \n",
       "995         0  ...         0        0              0           0          0   \n",
       "996         0  ...         0        0              0           0          0   \n",
       "997         0  ...         0        0              0           0          0   \n",
       "998         0  ...         0        0              0           0          0   \n",
       "999         0  ...         0        0              0           0          0   \n",
       "\n",
       "     wyoming  yakima  yonkers  yorba linda  yuma  \n",
       "0          0       0        0            0     0  \n",
       "1          0       0        0            0     0  \n",
       "2          0       0        0            0     0  \n",
       "3          0       0        0            0     0  \n",
       "4          0       0        0            0     0  \n",
       "..       ...     ...      ...          ...   ...  \n",
       "995        0       0        0            0     0  \n",
       "996        0       0        0            0     0  \n",
       "997        0       0        0            0     0  \n",
       "998        0       0        0            0     0  \n",
       "999        0       0        0            0     0  \n",
       "\n",
       "[1000 rows x 420 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5264d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "#Training dataset\n",
    "one_hot_df = pd.DataFrame(scaler.fit_transform(new_train_data.iloc[:, 4:]))\n",
    "\n",
    "mean_df = pd.DataFrame(one_hot_df.mean(axis=1), columns=['mean_feature'])\n",
    "\n",
    "new_train_data = pd.concat([new_train_data.iloc[:, 0:4], mean_df], axis=1)\n",
    "\n",
    "#Testing dataset\n",
    "one_hot_df = pd.DataFrame(scaler.fit_transform(new_test_data.iloc[:, 3:]))\n",
    "\n",
    "mean_df = pd.DataFrame(one_hot_df.mean(axis=1), columns=['mean_feature'])\n",
    "\n",
    "new_test_data = pd.concat([new_test_data.iloc[:, 0:3], mean_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdfc693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>mean_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>3.65</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.39</td>\n",
       "      <td>6.40</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.03</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>1.73</td>\n",
       "      <td>6.27</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>2.97</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>5.71</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.14</td>\n",
       "      <td>6.09</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>2.79</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        col3  col4  col5  col6  mean_feature\n",
       "0       3.52  0.03  2.32     0      0.000587\n",
       "1       0.99  3.65  5.06     0      0.000465\n",
       "2       6.39  6.40  5.77     0      0.001017\n",
       "3       4.03  3.23  0.06     0     -0.012115\n",
       "4       0.25  1.38  5.69     1      0.002421\n",
       "...      ...   ...   ...   ...           ...\n",
       "999995  1.73  6.27  4.70     0      0.001531\n",
       "999996  2.97  4.11  0.02     1      0.002210\n",
       "999997  5.71  5.07  4.97     0      0.000937\n",
       "999998  1.14  6.09  0.88     1      0.002598\n",
       "999999  2.79  6.10  0.69     1      0.001472\n",
       "\n",
       "[1000000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e63ce",
   "metadata": {},
   "source": [
    "Based on the data, it is known that the column 'mean_feature' has little impact on the prediction, therefore it will not be included as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828c42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features and labels fot following models\n",
    "train_labels = new_train_data.iloc[:, -2]\n",
    "train_features = new_train_data.loc[:, ['col3', 'col4', 'col5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e71b0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = new_test_data.loc[:, ['col3', 'col4', 'col5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96a15f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train dataset into train set and validate set \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(train_features, train_labels, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a29b98",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b0fe98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.4564656954657432\n"
     ]
    }
   ],
   "source": [
    "# Train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE\n",
    "y_predictions = model.predict(X_validate)\n",
    "train_rmse = sqrt(mean_squared_error(y_validate, y_predictions))\n",
    "print('Train RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e4e83",
   "metadata": {},
   "source": [
    "# Decision Tree  and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e8976",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5c1fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 7, 'min_samples_split': 10}\n",
      "Best cross-validation score: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# find the best paramater -- Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "regressor = DecisionTreeRegressor()\n",
    "\n",
    "# Define custom scoring function to calculate RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Create RMSE scorer\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "grid_search = GridSearchCV(regressor, param_grid, cv=5, scoring=rmse_scorer)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.sqrt(-grid_search.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1d32f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.4531867983098469\n"
     ]
    }
   ],
   "source": [
    "# we try best parameter max_depth=7, min_samples_split=10:\n",
    "model = DecisionTreeRegressor(max_depth=7, min_samples_split=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE\n",
    "y_predictions = model.predict(X_validate)\n",
    "train_rmse = sqrt(mean_squared_error(y_validate, y_predictions))\n",
    "print('Train RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db078334",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b983ec2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m rmse_scorer \u001b[38;5;241m=\u001b[39m make_scorer(rmse, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(rfc, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mrmse_scorer)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(grid_search\u001b[38;5;241m.\u001b[39mbest_params_))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest cross-validation score: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m-\u001b[39mgrid_search\u001b[38;5;241m.\u001b[39mbest_score_)))\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# find the best paramater -- Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rfc = RandomForestRegressor()\n",
    "\n",
    "# Define custom scoring function to calculate RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Create RMSE scorer\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=5, scoring=rmse_scorer)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.sqrt(-grid_search.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try best parameter:\n",
    "model = RandomForestRegressor(n_estimators=grid_search.best_params_['n_estimators'],\n",
    "                              max_depth=grid_search.best_params_['max_depth'], \n",
    "                              min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                              min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE\n",
    "y_predictions = model.predict(X_validate)\n",
    "train_rmse = sqrt(mean_squared_error(y_validate, y_predictions))\n",
    "print('Train RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461dfe2",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]} \n",
    "\n",
    "model = SVR()\n",
    "\n",
    "# Define custom scoring function to calculate RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Create RMSE scorer\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring=rmse_scorer)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.sqrt(-grid_search.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try best parameter:\n",
    "model = SVR(C=grid_search.best_params_['C'],\n",
    "            gamma=grid_search.best_params_['gamma'])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE\n",
    "y_predictions = model.predict(X_validate)\n",
    "train_rmse = sqrt(mean_squared_error(y_validate, y_predictions))\n",
    "print('Train RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbeee3f",
   "metadata": {},
   "source": [
    "## XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f1232d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "\n",
    "# Define custom scoring function to calculate RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "#=========================================================================\n",
    "# XGBoost regression: \n",
    "# Parameters: \n",
    "# n_estimators  \"Number of gradient boosted trees. Equivalent to number \n",
    "#                of boosting rounds.\"\n",
    "# learning_rate \"Boosting learning rate (also known as “eta”)\"\n",
    "# max_depth     \"Maximum depth of a tree. Increasing this value will make \n",
    "#                the model more complex and more likely to overfit.\" \n",
    "#=========================================================================\n",
    "regressor=xg.XGBRegressor(eval_metric=rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52d013e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.015, 'max_depth': 5, 'n_estimators': 700}\n",
      "Best cross-validation score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# set up our search grid\n",
    "param_grid = {\"max_depth\":    [4, 5],\n",
    "              \"n_estimators\": [500, 600, 700],\n",
    "              \"learning_rate\": [0.01, 0.015]}\n",
    "\n",
    "# Create RMSE scorer\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "grid_search = GridSearchCV(regressor, param_grid=param_grid, cv=5, scoring=rmse_scorer)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.sqrt(-grid_search.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bafe97bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.45170378234780295\n"
     ]
    }
   ],
   "source": [
    "regressor=xg.XGBRegressor(learning_rate = grid_search.best_params_[\"learning_rate\"],\n",
    "                           n_estimators  = grid_search.best_params_[\"n_estimators\"],\n",
    "                           max_depth     = grid_search.best_params_[\"max_depth\"],\n",
    "                           eval_metric=rmse)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE\n",
    "y_predictions = regressor.predict(X_validate)\n",
    "train_rmse = sqrt(mean_squared_error(y_validate, y_predictions))\n",
    "print('Train RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03571554",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cee024",
   "metadata": {},
   "source": [
    "## After comparing with the previous models, I have decided to use the XGBoost model to make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0caf1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = list(regressor.predict(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3cc075b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('labels.txt', 'w') as f:\n",
    "    f.writelines(map(lambda x: str(x) + '\\n', pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
